# Introducci√≥n a la √©tica de los datos

|![Alt text](./img/image.png)|
|:---:|
| √âtica de la ciencia de datos: nota de boceto de [@nitya](https://twitter.com/nitya)_ |

---

We are all data citizens living in a datafied world.

Todos somos ciudadanos de datos que vivimos en un mundo con datos.

Las tendencias del mercado nos dicen que en el a√±o 2022, 1 de cada 3 organizaciones grandes compro y vendio sus datos a trav√©s de [mercados e intercambios](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) en l√≠nea. Como **desarrolladores de aplicaciones**, nos resultar√° m√°s f√°cil y econ√≥mico integrar conocimientos basados ‚Äã‚Äãen datos y automatizaci√≥n basada en algoritmos en las experiencias diarias de los usuarios. Pero a medida que la IA se vuelve omnipresente, tambi√©n necesitaremos comprender los da√±os potenciales causados ‚Äã‚Äãpor la [utilizaci√≥n](https://www.youtube.com/watch?v=TQHs8SA1qpk) de tales algoritmos como armas a escala.

Las tendencias tambi√©n indican que crearemos y consumiremos m√°s de [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) de datos para 2025. Como **cient√≠ficos de datos**,esto nos brinda niveles de acceso a datos personales sin precedentes. Esto significa que podemos crear perfiles de comportamiento de los usuarios e influir en la toma de decisiones de manera que creen una [ilusi√≥n de libre elecci√≥n](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) y al mismo tiempo, impulsen potencialmente a los usuarios hacia los resultados que preferimos. Tambi√©n plantea preguntas m√°s amplias sobre la privacidad de los datos y la protecci√≥n de los usuarios.

La √©tica de los datos es ahora una barrera necesaria para la ciencia y la ingenier√≠a de datos, y nos ayuda a minimizar los da√±os potenciales y las consecuencias no deseadas de nuestras acciones basadas en datos. El [Gartner Hype Cycle for AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) dentifica tendencias relevantes en √©tica digital, IA responsable y gobernanza de la IA como impulsores clave de megatendencias m√°s amplias en torno a la _democratizaci√≥n_ e _industrializaci√≥n_ de la IA.

![Gartner's Hype Cycle for AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

En esta lecci√≥n, exploraremos el fascinante √°rea de la √©tica de los datos, desde conceptos y desaf√≠os centrales hasta estudios de casos y conceptos de IA aplicados como la gobernanza, que ayudan a establecer una cultura √©tica en equipos y organizaciones que trabajan con datos e IA.


## [Pre-lecture quiz](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) üéØ

## Definiciones basicas

Comencemos por comprender la terminolog√≠a b√°sica.

La palabra ‚Äú√©tica‚Äù proviene del [vocablo griego ‚Äúethikos‚Äù](https://en.wikipedia.org/wiki/Ethics) (y su ra√≠z ‚Äúethos‚Äù) que significa car√°cter o naturaleza moral .

**La √©tica** se trata de los valores compartidos y los principios morales que gobiernan nuestro comportamiento en la sociedad. La √©tica no se basa en leyes sino en normas ampliamente aceptadas sobre lo que es "lo correcto y lo incorrecto". Sin embargo, las consideraciones √©ticas pueden influir en las iniciativas de gobierno corporativo y las regulaciones gubernamentales que crean m√°s incentivos para el cumplimiento.

**La √âtica de Datos** es una [nueva rama de la √©tica](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) que "estudia y eval√∫a problemas morales relacionados con  _datos, algoritmos y pr√°cticas correspondientes_". Aqu√≠, **"los datos"**  se centran en acciones relacionadas con la generaci√≥n, el registro, la conservaci√≥n, el procesamiento, la difusi√≥n, el intercambio y el uso de los **"algoritmos"** se centran en la IA, los agentes, el aprendizaje autom√°tico y los robots, y las **"pr√°cticas"**  se centran en temas como la innovaci√≥n responsable. programaci√≥n, hacking y c√≥digos de √©tica.

**La √âtica Aplicada** es la [aplicaci√≥n pr√°ctica de consideraciones morales](https://en.wikipedia.org/wiki/Applied_ethics). Es el proceso de investigar activamente cuestiones √©ticas en el contexto de _acciones, productos y procesos del mundo real_,  y tomar medidas correctivas para que estos permanezcan alineados con nuestros valores √©ticos definidos.

**La cultura √©tica** consiste en [_poner en pr√°ctica la √©tica aplicada_](https://hbr.org/2019/05/how-to-design-an-ethical-organization) para garantizar que nuestros principios y pr√°cticas √©ticos se adopten de manera consistente y escalable en toda la organizaci√≥n. Las culturas √©ticas exitosas definen principios √©ticos en toda la organizaci√≥n, brindan incentivos significativos para el cumplimiento y refuerzan las normas √©ticas al alentar y amplificar los comportamientos deseados en todos los niveles de la organizaci√≥n.

## Conceptos de √©tica

En esta secci√≥n, discutiremos conceptos como **valores compartidos** (principios) y **desaf√≠os √©ticos** (problemas) para la √©tica de los datos, y exploraremos **estudios de casos**que lo ayudar√°n a comprender estos conceptos en contextos del mundo real.

### 1. Principios √©ticos

Cada estrategia de √©tica de datos comienza con la definici√≥n de _principios √©ticos_ - los "valores compartidos" que describen comportamientos aceptables y gu√≠an acciones de cumplimiento en nuestros proyectos de datos e inteligencia artificial. Puede definirlos a nivel individual o de equipo. Sin embargo, la mayor√≠a de las organizaciones grandes los describen en una declaraci√≥n o marco de misi√≥n √©tica de la IA que se define a nivel corporativo y se aplica de manera consistente en todos los equipos.

**Ejemplo:** la declaraci√≥n de misi√≥n [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai) de Microsoft dice: _"Estamos comprometidos con el avance de la IA impulsada por principios √©ticos que ponen a las personas en primer lugar"_ -  identificando seis principios √©ticos en el marco a continuaci√≥n:

![Responsible AI at Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Exploremos brevemente estos principios. _La transparencia_ y _la rendici√≥n de cuentas_ on valores fundamentales sobre los que se basan otros principios, as√≠ que comencemos por ah√≠:

* [**La rendici√≥n de cuentas**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) hace que los profesionales sean responsables de sus operaciones de datos e inteligencia artificial, y del cumplimiento de estos principios √©ticos.
* [**La transparencia**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6)  garantiza que los datos y las acciones de la IA sean comprensibles (interpretables) para los usuarios, explicando el qu√© y el por qu√© detr√°s de las decisiones.
* [**Equidad**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - se centra en garantizar que la IA trate a todas las personas de manera justa, abordando cualquier sesgo sociot√©cnico sist√©mico o impl√≠cito en los datos y sistemas.
* [**Fiabilidad y seguridad**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - garantiza que la IA se comporte de forma coherente con los valores definidos, minimizando posibles da√±os o consecuencias no deseadas.
* [**Privacidad y seguridad**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se trata de comprender el linaje de datos y brindar privacidad de datos y protecciones relacionadas a los usuarios.
* [**Inclusi√≥n**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se trata de dise√±ar soluciones de IA con intenci√≥n, adapt√°ndolas para satisfacer una amplia gama de necesidades y capacidades humanas.

> üö® Piense en cu√°l podr√≠a ser su declaraci√≥n de misi√≥n de √©tica de datos. Explore los marcos √©ticos de IA de otras organizaciones: aqu√≠ hay ejemplos de [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) y [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). ¬øQu√© valores compartidos tienen en com√∫n? ¬øC√≥mo se relacionan estos principios con el producto o la industria de IA en la que operan?

### 2. Desaf√≠os √©ticos

Una vez que hayamos definido los principios √©ticos, el siguiente paso es evaluar nuestros datos y acciones de IA para ver si se alinean con esos valores compartidos. Piense en sus acciones en dos categor√≠as: recopilaci√≥n de datos y dise√±o de algoritmos. 

Con la recopilaci√≥n de datos, las acciones probablemente involucrar√°n **datos personales** o informaci√≥n de identificaci√≥n personal (PII) de personas vivas identificables. Esto incluye [diversos elementos de datos no personales](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) que identifican colectivamente a un individuo. Los desaf√≠os √©ticos pueden estar relacionados con la privacidad de los datos , la propiedad de los datos y temas relacionados como el consentimiento informado y los derechos de propiedad intelectual de los usuarios.

Con el dise√±o de algoritmos, las acciones implicar√°n recopilar y seleccionar **conjuntos de datos**, uego usarlos para entrenar e implementar **modelos de datos** que predigan resultados o automaticen decisiones en contextos del mundo real. Los desaf√≠os √©ticos pueden surgir del sesgo del conjunto de datos , problemas de calidad de los datos , injusticia y tergiversaci√≥n en los algoritmos, incluidos algunos problemas que son de naturaleza sist√©mica.

En ambos casos, los desaf√≠os √©ticos resaltan √°reas donde nuestras acciones pueden entrar en conflicto con nuestros valores compartidos. Para detectar, mitigar, minimizar o eliminar estas preocupaciones, debemos hacer preguntas morales de "s√≠ o no" relacionadas con nuestras acciones y luego tomar las acciones correctivas necesarias. Echemos un vistazo a algunos desaf√≠os √©ticos y las cuestiones morales que plantean:


#### 2.1 Propiedad de los datos

La recopilaci√≥n de datos a menudo implica datos personales que pueden identificar a los interesados. [La propiedad de los datos](https://permission.io/blog/data-ownership) se refiere al control y [_los derechos del usuario_](https://permission.io/blog/data-ownership) relacionados con la creaci√≥n, el procesamiento y la difusi√≥n de datos.

Las preguntas morales que debemos plantearnos son: 
 * ¬øA qui√©n pertenecen los datos? (usuario u organizaci√≥n)
 * ¬øQu√© derechos tienen los interesados? (ej: acceso, borrado, portabilidad)
 * ¬øQu√© derechos tienen las organizaciones? (por ejemplo: rectificar rese√±as de usuarios maliciosos)

#### 2.2 Consentimiento informado

[El consentimiento informado](https://legaldictionary.net/informed-consent/) define el acto por el cual los usuarios aceptan una acci√≥n (como la recopilaci√≥n de datos) con una comprensi√≥n completa de los hechos relevantes, incluido el prop√≥sito, los riesgos potenciales y las alternativas.

Las preguntas para explorar aqu√≠ son:
 * ¬øEl usuario (titular de los datos) dio permiso para la captura y el uso de datos?
 * ¬øEl usuario entendi√≥ el prop√≥sito para el cual se capturaron esos datos?
 * ¬øEl usuario entendi√≥ los riesgos potenciales de su participaci√≥n?

#### 2.3 Propiedad intelectual

[La propiedad intelectual](https://en.wikipedia.org/wiki/Intellectual_property) se refiere a creaciones intangibles resultantes de la iniciativa humana, que pueden tener valor econ√≥mico para individuos o empresas.

Las preguntas para explorar aqu√≠ son:
 * ¬øLos datos recopilados ten√≠an valor econ√≥mico para un usuario o empresa?
 * ¬øEl usuario tiene propiedad intelectual aqu√≠?
 * ¬øLa **organizaci√≥n** tiene propiedad intelectual aqu√≠?
 * Si estos derechos existen, ¬øc√≥mo los protegemos?

#### 2.4 Privacidad de datos

[La privacidad de los datos](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) o la privacidad de la informaci√≥n se refiere a la preservaci√≥n de la privacidad del usuario y la protecci√≥n de la identidad del usuario con respecto a la informaci√≥n de identificaci√≥n personal.

Las preguntas para explorar aqu√≠ son:
 * ¬øEst√°n los datos (personales) de los usuarios protegidos contra ataques y filtraciones?
 * ¬øLos datos de los usuarios son accesibles solo para usuarios y contextos autorizados?
 * ¬øSe preserva el anonimato de los usuarios cuando se comparten o difunden datos?
 * ¬øSe puede desidentificar a un usuario de conjuntos de datos anonimizados?


#### 2.5 Derecho al olvido
El [Derecho al Olvido](https://en.wikipedia.org/wiki/Right_to_be_forgotten) or [Derecho de Supresi√≥n](https://www.gdpreu.org/right-to-be-forgotten/)proporciona protecci√≥n adicional de datos personales a los usuarios. Espec√≠ficamente, otorga a los usuarios el derecho de solicitar la eliminaci√≥n o eliminaci√≥n de datos personales de b√∫squedas en Internet y otras ubicaciones, bajo circunstancias espec√≠ficas , permiti√©ndoles un nuevo comienzo en l√≠nea sin que se les apliquen acciones pasadas.

Las preguntas para explorar aqu√≠ son:
 * ¬øEl sistema permite a los interesados ‚Äã‚Äãsolicitar la supresi√≥n?
 * ¬øLa retirada del consentimiento del usuario deber√≠a provocar un borrado autom√°tico?
 * ¬øSe recopilaron datos sin consentimiento o por medios ilegales?
 * ¬øCumplimos con las regulaciones gubernamentales sobre privacidad de datos?


#### 2.6 Sesgo del conjunto de datos

El sesgo de conjunto de datos o [recopilaci√≥n](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) consiste en seleccionar un subconjunto de datos no representativo para el desarrollo de algoritmos, creando una posible injusticia en los resultados para diversos grupos. Los tipos de sesgo incluyen sesgo de selecci√≥n o muestreo, sesgo de voluntario y sesgo de instrumento.

Las preguntas para explorar aqu√≠ son:
 * ¬øContratamos a un conjunto representativo de interesados?
 * ¬øProbamos nuestro conjunto de datos recopilados o seleccionados para detectar diversos sesgos?
 * ¬øPodemos mitigar o eliminar cualquier sesgo descubierto?

#### 2.7 Calidad de los datos

[Data Quality](https://lakefs.io/data-quality-testing/) analiza la validez del conjunto de datos seleccionado utilizado para desarrollar nuestros algoritmos, verificando si las caracter√≠sticas y los registros cumplen con los requisitos del nivel de precisi√≥n y coherencia necesarios para nuestro prop√≥sito de IA.

Las preguntas para explorar aqu√≠ son:
 * ¬øCaptamos caracter√≠sticas v√°lidas para nuestro caso de uso?
 * ¬øSe capturaron datos de manera consistente en diversas fuentes de datos?
 * ¬øEst√° completo el conjunto de datos para diversas condiciones o escenarios?
 * ¬øSe captura la informaci√≥n con precisi√≥n para reflejar la realidad?

#### 2.8 Equidad del algoritmo

[La equidad del algoritmo ](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) verifica si el dise√±o del algoritmo discrimina sistem√°ticamente a subgrupos espec√≠ficos de interesados, lo que genera [da√±os potenciales](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) en la asignaci√≥n (donde se niegan o retienen recursos de ese grupo) y la calidad del servicio (donde la IA no es tan precisa para algunos subgrupos como lo es). es para otros.

Las preguntas para explorar aqu√≠ son:
 * ¬øEvaluamos la precisi√≥n del modelo para diversos subgrupos y condiciones?
 * ¬øExaminamos el sistema en busca de da√±os potenciales (por ejemplo, estereotipos)?
 * ¬øPodemos revisar los datos o volver a entrenar los modelos para mitigar los da√±os identificados?

Explore recursos como [las listas de verificaci√≥n de equidad de IA](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) para obtener m√°s informaci√≥n.

#### 2.9 Tergiversaci√≥n

[La tergiversaci√≥n de datos](https://www.sciencedirect.com/topics/computer-science/misrepresentation) consiste en preguntar si estamos comunicando conocimientos a partir de datos informados honestamente de manera enga√±osa para respaldar una narrativa deseada.

Las preguntas para explorar aqu√≠ son:
 * ¬øEstamos reportando datos incompletos o inexactos?
 * ¬øEstamos visualizando los datos de una manera que genera conclusiones enga√±osas?
 * ¬øEstamos utilizando t√©cnicas estad√≠sticas selectivas para manipular los resultados?
 * ¬øExisten explicaciones alternativas que puedan ofrecer una conclusi√≥n diferente?

#### 2.10 Libre Elecci√≥n

La [ilusi√≥n de la libre elecci√≥n](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice)  ocurre cuando las "arquitecturas de elecci√≥n" del sistema utilizan algoritmos de toma de decisiones para empujar a las personas a tomar un resultado preferido mientras parecen darles opciones y control. Estos [patrones oscuros](https://www.darkpatterns.org/) pueden causar da√±os sociales y econ√≥micos a los usuarios. Debido a que las decisiones de los usuarios afectan los perfiles de comportamiento, estas acciones potencialmente impulsan decisiones futuras que pueden amplificar o extender el impacto de estos da√±os.

Las preguntas para explorar aqu√≠ son:
 * ¬øEntendi√≥ el usuario las implicaciones de tomar esa decisi√≥n?
 * ¬øEl usuario conoc√≠a las opciones (alternativas) y los pros y los contras de cada una?
 * ¬øPuede el usuario revertir una elecci√≥n automatizada o influenciada m√°s adelante?

### 3. Estudios de caso

To put these ethical challenges in real-world contexts, it helps to look at case studies that highlight the potential harms and consequences to individuals and society, when such ethics violations are overlooked. 

Here are a few examples:

| Ethics Challenge | Case Study  | 
|--- |--- |
| **Consentimiento informado** | 1972 - [Estudio de s√≠filis de Tuskegee](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) -  A los hombres afroamericanos que participaron en el estudio se les prometi√≥ atenci√≥n m√©dica gratuita, pero los investigadores los enga√±aron y no informaron a los sujetos sobre su diagn√≥stico ni sobre la disponibilidad del tratamiento. Muchos sujetos murieron y sus parejas o ni√±os resultaron afectados; el estudio dur√≥ 40 a√±os. | 
| **Privacidad de datos** |  2007 - El [premio de datos de Netflix](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) proporcion√≥ a los investigadores 10 millones de clasificaciones de pel√≠culas an√≥nimas de 50.000 clientes para ayudar a mejorar los algoritmos de recomendaci√≥n. Sin embargo, los investigadores pudieron correlacionar datos an√≥nimos con datos de identificaci√≥n personal en conjuntos de datos externos (por ejemplo, comentarios de IMDb), "desanonimizando" efectivamente a algunos suscriptores de Netflix.|
| **Sesgo de colecci√≥n**  | 2013 -  la ciudad de Boston [desarroll√≥ Street Bump](https://www.boston.gov/transportation/street-bump), una aplicaci√≥n que permit√≠a a los ciudadanos informar sobre baches, brindando a la ciudad mejores datos sobre las carreteras para encontrar y solucionar problemas. Sin embargo, [las personas de los grupos de ingresos m√°s bajos ten√≠an menos acceso a autom√≥viles y tel√©fonos](https://hbr.org/2013/04/the-hidden-biases-in-big-data), lo que hac√≠a que sus problemas viales fueran invisibles en esta aplicaci√≥n. Los desarrolladores trabajaron con acad√©micos para abordar cuestiones de equidad en materia de acceso equitativo y brechas digitales. |
| **Equidad algor√≠tmica**  | 2018 - El [estudio Gender Shades](http://gendershades.org/overview.html) del MIT evalu√≥ la precisi√≥n de los productos de IA de clasificaci√≥n de g√©nero, exponiendo brechas en la precisi√≥n para mujeres y personas de color. Una [Apple Card de 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) parec√≠a ofrecer menos cr√©dito a las mujeres que a los hombres. Ambos ilustraron problemas de sesgo algor√≠tmico que conducen a da√±os socioecon√≥micos. |
| **Tergiversaci√≥n de datos** | 2020 - El [Departamento de Salud P√∫blica de Georgia public√≥ gr√°ficos de COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) que parec√≠an enga√±ar a los ciudadanos sobre las tendencias en los casos confirmados con un orden no cronol√≥gico en el eje x. Esto ilustra la tergiversaci√≥n mediante trucos de visualizaci√≥n. |
| **Ilusi√≥n de libre elecci√≥n** | 2020 -  la aplicaci√≥n de aprendizaje [ABCmouse pag√≥ 10 millones de d√≥lares para resolver una queja de la FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) en la que los padres se vieron atrapados en el pago de suscripciones que no pod√≠an cancelar. Esto ilustra patrones oscuros en las arquitecturas de elecci√≥n, donde los usuarios fueron empujados hacia elecciones potencialmente da√±inas. |
| **Privacidad de datos y derechos del usuario** | 2021 - [La filtraci√≥n de datos](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) de Facebook expuso datos de 530 millones de usuarios, lo que result√≥ en un acuerdo de 5 mil millones de d√≥lares para la FTC. Sin embargo, se neg√≥ a notificar a los usuarios sobre la infracci√≥n que violaba los derechos de los usuarios en materia de transparencia y acceso a los datos. |

Want to explore more case studies? Check out these resources:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - dilemas √©ticos en diversas industrias.
* [Curso de √©tica de la ciencia de datos :](https://www.coursera.org/learn/data-science-ethics#syllabus) - exploraci√≥n de estudios de casos emblem√°ticos.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - lista de verificaci√≥n de Deon con ejemplos.

> üö® Piensa en los estudios de casos que has visto: ¬øhas experimentado o te has visto afectado por un desaf√≠o √©tico similar en tu vida? ¬øSe le ocurre al menos otro estudio de caso que ilustre uno de los desaf√≠os √©ticos que hemos discutido en esta secci√≥n?

## √âtica Aplicada

Hemos hablado sobre conceptos, desaf√≠os y estudios de casos de √©tica en contextos del mundo real. Pero, ¬øc√≥mo empezamos a aplicar principios y pr√°cticas √©ticas en nuestros proyectos? ¬øY c√≥mo ponemos en pr√°ctica estas pr√°cticas para una mejor gobernanza? Exploremos algunas soluciones del mundo real:

### 1. C√≥digos Profesionales

Los c√≥digos profesionales ofrecen una opci√≥n para que las organizaciones "incentiven" a sus miembros a apoyar sus principios √©ticos y su declaraci√≥n de misi√≥n. Los c√≥digos son pautas morales para el comportamiento profesional, que ayudan a los empleados o miembros a tomar decisiones que se alineen con los principios de su organizaci√≥n. Son tan buenos como el cumplimiento voluntario de los miembros; sin embargo, muchas organizaciones ofrecen recompensas y sanciones adicionales para motivar el cumplimiento por parte de los miembros.

Ejemplos incluyen:

 * C√≥digo de √©tica de [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) .
 * C√≥digo de conducta [de la Asociaci√≥n de ciencia de datos (creado en 2013)](http://datascienceassn.org/code-of-conduct.html). 
 * [C√≥digo de √âtica y Conducta Profesional de ACM](https://www.acm.org/code-of-ethics) (desde 1993)

> üö® ¬øPertenece a una organizaci√≥n profesional de ingenier√≠a o ciencia de datos? Explore su sitio para ver si definen un c√≥digo de √©tica profesional. ¬øQu√© dice esto sobre sus principios √©ticos? ¬øC√≥mo est√°n "incentivando" a los miembros a seguir el c√≥digo?

### 2. Ethics Checklists

Si bien los c√≥digos profesionales definen el comportamiento √©tico requerido por parte de los profesional, [tienen limitaciones conocidas](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) en su aplicaci√≥n, particularmente en proyectos a gran escala. En cambio, muchos expertos en ciencia de datos [abogan por listas de verificaci√≥n](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), que pueden **conectar los principios con las pr√°cticas** de maneras m√°s deterministas y pr√°cticas.

Las listas de verificaci√≥n convierten las preguntas en tareas de "s√≠/no" que se pueden poner en pr√°ctica, lo que permite realizar un seguimiento de ellas como parte de los flujos de trabajo de lanzamiento de productos est√°ndar.

Ejemplos incluyen:
 * [Deon](https://deon.drivendata.org/) - una lista de verificaci√≥n de √©tica de datos de uso general creada a partir de [recomendaciones de la industria](https://deon.drivendata.org/#checklist-citations) con una herramienta de l√≠nea de comandos para una f√°cil integraci√≥n.
 * [Lista de verificaci√≥n de auditor√≠a de privacidad](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - proporciona orientaci√≥n general para las pr√°cticas de manejo de informaci√≥n desde perspectivas de exposici√≥n legal y social.
 * [Lista de verificaci√≥n de equidad de IA](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - creada por profesionales de la IA para respaldar la adopci√≥n e integraci√≥n de controles de equidad en los ciclos de desarrollo de la IA.
 * [22 preguntas sobre √©tica en datos e IA](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - marco m√°s abierto, estructurado para la exploraci√≥n inicial de cuestiones √©ticas en contextos de dise√±o, implementaci√≥n y organizaci√≥n.

### 3. Normas de √âtica

La √©tica consiste en definir valores compartidos y hacer lo correcto de forma voluntaria. **El cumplimiento**  consiste en seguir la ley siempre y cuando est√© definida. **La gobernanza** cubre ampliamente todas las formas en que las organizaciones operan para hacer cumplir los principios √©ticos y cumplir con las leyes establecidas.

Hoy en d√≠a, la gobernanza adopta dos formas dentro de las organizaciones. En primer lugar, se trata de definir principios **√©ticos de IA**  y establecer pr√°cticas para operacionalizar la adopci√≥n en todos los proyectos relacionados con la IA en la organizaci√≥n. En segundo lugar, se trata de cumplir con todas **las normas de protecci√≥n de datos** exigidas por el gobierno para las regiones en las que opera.

Ejemplos de normativa de protecci√≥n de datos y privacidad:

 * `1974`, [Ley de Privacidad de EE. UU](https://www.justice.gov/opcl/privacy-act-1974) - regulates _federal govt._ collection, use ,and disclosure of personal information.
 * `1996`, [Ley de Responsabilidad y Portabilidad del Seguro M√©dico de EE. UU. (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) -  protege los datos de salud personales.
 * `1998`, [Ley de protecci√≥n de la privacidad infantil en l√≠nea de EE. UU. (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - protege la privacidad de los datos de ni√±os menores de 13 a√±os.
 * `2018`, [Reglamento general de protecci√≥n de datos (GDPR)](https://gdpr-info.eu/) - proporciona derechos de usuario, protecci√≥n de datos y privacidad.
 * `2018`, [La Ley de Privacidad del Consumidor de California (CCPA)](https://www.oag.ca.gov/privacy/ccpa)  otorga a los consumidores m√°s derechos sobre sus datos (personales).
 * `2021`, Acaba de aprobarse [la Ley de Protecci√≥n de Informaci√≥n Personal](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) de China , que crea una de las regulaciones de privacidad de datos en l√≠nea m√°s estrictas del mundo.

> üö®  El RGPD (Reglamento General de Protecci√≥n de Datos) definido por la Uni√≥n Europea sigue siendo una de las regulaciones de privacidad de datos m√°s influyentes en la actualidad. ¬øSab√≠as que tambi√©n define [8 derechos de los usuarios ](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) para proteger la privacidad digital y los datos personales de los ciudadanos? Aprenda qu√© son y por qu√© son importantes.


### 4. Cultura √©tica

Tenga en cuenta que sigue existiendo una brecha intangible entre el cumplimiento (hacer lo suficiente para cumplir "la letra de la ley") y abordar [cuestiones sist√©micas](https://www.coursera.org/learn/data-science-ethics/home/week/4)  (como la osificaci√≥n, la asimetr√≠a de la informaci√≥n y la injusticia distributiva) que pueden acelerar el uso de la IA como arma. 

Esto √∫ltimo requiere [collaborative approaches to defining ethics cultures](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) que creen conexiones emocionales y valores compartidos consistentes entre las organizaciones de la industria. Esto exige [culturas de √©tica de datos m√°s formalizadas](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) en las organizaciones, permitiendo a cualquiera tirar [del cord√≥n de Andon](https://en.wikipedia.org/wiki/Andon_(manufacturing))  (para plantear inquietudes √©ticas en las primeras etapas del proceso) y hacer de las evaluaciones √©ticas (por ejemplo, en la contrataci√≥n) un criterio central en la formaci√≥n del equipo en proyectos de IA.

---
## [Post-lecture quiz](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/3) üéØ

## Revisi√≥n y autoestudio

Los cursos y libros ayudan a comprender los conceptos y desaf√≠os b√°sicos de la √©tica, mientras que los estudios de casos y las herramientas ayudan con las pr√°cticas √©ticas aplicadas en contextos del mundo real. Aqu√≠ hay algunos recursos para comenzar.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lecci√≥n sobre equidad, de Microsoft.
* [Principios de IA responsable](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) -  ruta de aprendizaje gratuita de Microsoft Learn.
* [√âtica y ciencia de datos](https://resources.oreilly.com/examples/0636920203964) - Libro electr√≥nico de O'Reilly (M. Loukides, H. Mason et. al)
* [√âtica de la ciencia de datos](https://www.coursera.org/learn/data-science-ethics#syllabus) - curso en l√≠nea de la Universidad de Michigan.
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - estudios de casos de la Universidad de Texas.

# Tarea:

[Escriba un estudio de caso de √©tica de datos](Tarea.md).
