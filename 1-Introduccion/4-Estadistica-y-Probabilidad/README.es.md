# Una breve introducci√≥n a la estad√≠stica y la probabilidad

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](./img/image.png)|
|:---:|
| Estad√≠stica y probabilidad - _Sketchnote de [@nitya](https://twitter.com/nitya)_ |

La estad√≠stica y la teor√≠a de la probabilidad son dos √°reas de las matem√°ticas altamente relacionadas y muy relevantes para la ciencia de datos. Es posible operar con datos sin un conocimiento profundo de matem√°ticas, pero es mejor conocer al menos algunos conceptos b√°sicos. Aqu√≠ presentaremos una breve introducci√≥n que le ayudar√° a empezar.

[![Video intro](./img/image-1.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Prueba previa a la conferencia](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Probabilidad y variables aleatorias
**La probabilidad** es un n√∫mero entre 0 y 1 que expresa qu√© tan probable es un **evento** . Se define como una cantidad de resultados positivos (que conducen al evento), dividido por el n√∫mero total de resultados, dado que todos los resultados son igualmente probables. Por ejemplo, cuando tiramos un dado, la probabilidad de que obtenga un n√∫mero par es 3/6 = 0,5.

Cuando hablamos de eventos, utilizamos **variables aleatorias** . Por ejemplo, la variable aleatoria que representa un n√∫mero obtenido al lanzar un dado tomar√≠a valores del 1 al 6. El conjunto de n√∫meros del 1 al 6 se llama **espacio muestral** . Podemos hablar de la probabilidad de que una variable aleatoria tome un determinado valor, por ejemplo P(X=3)=1/6.

La variable aleatoria del ejemplo anterior se llama **discreta** porque tiene un espacio muestral contable, es decir, hay valores separados que se pueden enumerar. Hay casos en los que el espacio muestral es un rango de n√∫meros reales o el conjunto completo de n√∫meros reales. Estas variables se denominan continuas . Un buen ejemplo es el momento en que llega el autob√∫s.

## Distribuci√≥n de probabilidad
En el caso de variables aleatorias discretas, es f√°cil describir la probabilidad de cada evento mediante una funci√≥n P(X). Para cada valor s del espacio muestral S dar√° un n√∫mero de 0 a 1, de modo que la suma de todos los valores de P(X=s) para todos los eventos ser√≠a 1.

La distribuci√≥n discreta m√°s conocida es **la distribuci√≥n uniforme** , en la que existe un espacio muestral de N elementos, con igual probabilidad de 1/N para cada uno de ellos.

Es m√°s dif√≠cil describir la distribuci√≥n de probabilidad de una variable continua, con valores extra√≠dos de alg√∫n intervalo [a,b], o del conjunto completo de n√∫meros reales ‚Ñù. Consideremos el caso de la hora de llegada del autob√∫s. De hecho, para cada hora exacta de llegada t , la probabilidad de que un autob√∫s llegue exactamente a esa hora es 0.

> Ahora sabes que los eventos con probabilidad 0 ocurren, ¬°y muy a menudo! ¬°Al menos cada vez que llega el autob√∫s!

Solo podemos hablar de la probabilidad de que una variable caiga en un intervalo dado de valores, por ejemplo. P(t<sub>1</sub>&le;X&lt;t<sub>2</sub>). En este caso, la distribuci√≥n de probabilidad se describe mediante una **funci√≥n de densidad de probabilidad** p(x), tal que

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](./img/image-2.png)

Un an√°logo continuo de la distribuci√≥n uniforme se llama **uniforme continuo**, que se define en un intervalo finito. La probabilidad de que el valor X caiga en un intervalo de longitud l es proporcional a l y aumenta hasta 1.

Otra distribuci√≥n importante es **la distribuci√≥n normal**, de la que hablaremos con m√°s detalle a continuaci√≥n.

## Media, varianza y desviaci√≥n est√°ndar

Supongamos que extraemos una secuencia de n muestras de una variable aleatoria X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Podemos definir el valor medio (o promedio aritm√©tico ) de la secuencia de la manera tradicional como (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. A medida que aumentamos el tama√±o de la muestra (es decir, tomamos el l√≠mite con n‚Üí‚àû), obtendremos la media (tambi√©n llamada expectativa ) de la distribuci√≥n. Denotaremos la expectativa por E (x).

> Se puede demostrar que para cualquier distribuci√≥n discreta con valores {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} y probabilidades correspondientes  p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, la expectativa ser√≠a igual a E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Para identificar hasta qu√© punto se distribuyen los valores, podemos calcular la varianza &sigma;<sup>2</sup>  = &sum;(x<sub>i</sub> - &mu;)<sup>2</sup>/n, donde Œº es la media de la secuencia. El valor œÉ se llama desviaci√≥n est√°ndar y &sigma;<sup>2</sup> se llama varianza.

## Moda, mediana y cuartiles

A veces, la media no representa adecuadamente el valor "t√≠pico" de los datos. Por ejemplo, cuando hay algunos valores extremos que est√°n completamente fuera de rango, pueden afectar la media. Otra buena indicaci√≥n es una mediana , un valor tal que la mitad de los puntos de datos son inferiores y la otra mitad superiores.

Para ayudarnos a comprender la distribuci√≥n de los datos, resulta √∫til hablar de cuartiles :

- El primer cuartil, o Q1, es un valor tal que el 25% de los datos se encuentran por debajo de √©l.
- El tercer cuartil, o Q3, es un valor en el que el 75% de los datos se encuentran por debajo de √©l.

Gr√°ficamente podemos representar la relaci√≥n entre la mediana y los cuartiles en un diagrama llamado diagrama de caja:

![Alt text](./img/image3.png)

Aqu√≠ tambi√©n calculamos el rango intercuartil IQR=Q3-Q1, y los llamados valores at√≠picos : valores que se encuentran fuera de los l√≠mites [Q1-1,5 _IQR,Q3+1,5_ IQR].

Para una distribuci√≥n finita que contiene una peque√±a cantidad de valores posibles, un buen valor "t√≠pico" es el que aparece con m√°s frecuencia, lo que se llama moda . A menudo se aplica a datos categ√≥ricos, como los colores. Consideremos una situaci√≥n en la que tenemos dos grupos de personas: algunos que prefieren el rojo y otros que prefieren el azul. Si codificamos los colores por n√∫meros, el valor medio de un color favorito estar√≠a en alg√∫n lugar del espectro naranja-verde, lo que no indica la preferencia real por ninguno de los grupos. Sin embargo, la moda ser√≠a uno de los colores, o ambos colores, si el n√∫mero de personas que votan por ellos es igual (en este caso llamamos a la muestra multimodal ).

## Datos del mundo real

Cuando analizamos datos de la vida real, a menudo no son variables aleatorias como tales, en el sentido de que no realizamos experimentos con resultados desconocidos. Por ejemplo, considere un equipo de jugadores de b√©isbol y sus datos corporales, como altura, peso y edad. Esos n√∫meros no son exactamente aleatorios, pero aun as√≠ podemos aplicar los mismos conceptos matem√°ticos. Por ejemplo, una secuencia de pesos de las personas puede considerarse como una secuencia de valores extra√≠dos de alguna variable aleatoria. A continuaci√≥n se muestra la secuencia de pesos de los jugadores de b√©isbol reales de la [Major League Baseball](http://mlb.mlb.com/index.jsp) tomados de [este conjunto de datos](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (para su comodidad, solo se muestran los primeros 20 valores):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```
> **Nota**: Para ver el ejemplo de c√≥mo trabajar con este conjunto de datos, consulte el cuaderno adjunto . Tambi√©n hay una serie de desaf√≠os a lo largo de esta lecci√≥n y puede completarlos agregando c√≥digo a ese cuaderno. Si no est√° seguro de c√≥mo operar con datos, no se preocupe: volveremos a trabajar con datos usando Python m√°s adelante. Si no sabe c√≥mo ejecutar c√≥digo en Jupyter Notebook, consulte [este art√≠culo](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Aqu√≠ est√° el diagrama de caja que muestra la media, la mediana y los cuartiles de nuestros datos:

![Alt text](./img/image4.png)

Dado que nuestros datos contienen informaci√≥n sobre diferentes roles de los jugadores , tambi√©n podemos hacer el diagrama de caja por rol; nos permitir√° tener una idea de c√≥mo los valores de los par√°metros difieren entre los roles. Esta vez consideraremos la altura:

![Alt text](./img/image5.png)

Este diagrama sugiere que, en promedio, la altura de los primera base es mayor que la altura de los segunda base. M√°s adelante en esta lecci√≥n aprenderemos c√≥mo podemos probar esta hip√≥tesis de manera m√°s formal y c√≥mo demostrar que nuestros datos son estad√≠sticamente significativos para demostrarlo.

> Cuando trabajamos con datos del mundo real, asumimos que todos los puntos de datos son muestras extra√≠das de alguna distribuci√≥n de probabilidad. Esta suposici√≥n nos permite aplicar t√©cnicas de aprendizaje autom√°tico y construir modelos predictivos funcionales.

Para ver cu√°l es la distribuci√≥n de nuestros datos, podemos trazar una gr√°fica llamada histograma . El eje X contendr√≠a una cantidad de intervalos de peso diferentes (los llamados contenedores ), y el eje vertical mostrar√≠a la cantidad de veces que nuestra muestra de variable aleatoria estuvo dentro de un intervalo determinado.

![Alt text](image.png)

En este histograma se puede ver que todos los valores se centran en torno a cierto peso medio y cuanto m√°s nos alejamos de ese peso, menos pesos de ese valor se encuentran. Es decir, es muy improbable que el peso de un jugador de b√©isbol sea muy diferente del peso medio. La variaci√≥n de las ponderaciones muestra hasta qu√© punto es probable que las ponderaciones difieran de la media.

> Si tomamos el peso de otras personas, no de la liga de b√©isbol, es probable que la distribuci√≥n sea diferente. Sin embargo, la forma de la distribuci√≥n ser√° la misma, pero la media y la varianza cambiar√°n. Entonces, si entrenamos nuestro modelo en jugadores de b√©isbol, es probable que d√© resultados incorrectos cuando se aplica a estudiantes de una universidad, porque la distribuci√≥n subyacente es diferente.

## Distribuci√≥n normal

La distribuci√≥n de pesos que hemos visto anteriormente es muy t√≠pica y muchas mediciones del mundo real siguen el mismo tipo de distribuci√≥n, pero con media y varianza diferentes. Esta distribuci√≥n se llama distribuci√≥n normal y juega un papel muy importante en estad√≠stica.

Usar la distribuci√≥n normal es una forma correcta de generar pesos aleatorios de posibles jugadores de b√©isbol. Una vez que conocemos el peso medio `mean` y la desviaci√≥n est√°ndar `std`, podemos generar 1000 muestras de peso de la siguiente manera:

```python
samples = np.random.normal(mean,std,1000)
``` 

Si trazamos el histograma de las muestras generadas veremos una imagen muy similar a la que se muestra arriba. Y si aumentamos el n√∫mero de muestras y el n√∫mero de contenedores, podemos generar una imagen de una distribuci√≥n normal que se acerque m√°s a la ideal:

![Alt text](./img/image7.png)

_Distribuci√≥n normal con media = 0 y std.dev = 1_

## Intervalos de confianza
Cuando hablamos de pesos de los jugadores de b√©isbol, asumimos que existe cierta variable aleatoria W que corresponde a la distribuci√≥n de probabilidad ideal de los pesos de todos los jugadores de b√©isbol (la llamada poblaci√≥n ). Nuestra secuencia de pesos corresponde a un subconjunto de todos los jugadores de b√©isbol al que llamamos muestra . Una pregunta interesante es: ¬øpodemos conocer los par√°metros de distribuci√≥n de W, es decir, la media y la varianza de la poblaci√≥n?

La respuesta m√°s sencilla ser√≠a calcular la media y la varianza de nuestra muestra. Sin embargo, podr√≠a suceder que nuestra muestra aleatoria no represente con precisi√≥n a la poblaci√≥n completa. Por tanto, tiene sentido hablar de intervalo de confianza .

> **El intervalo de confianza** es la estimaci√≥n de la media verdadera de la poblaci√≥n dada nuestra muestra, cuya precisi√≥n es una cierta probabilidad (o nivel de confianza ).

Supongamos que tenemos una muestra X<sub>1</sub>, ..., X<sub>n</sub> de nuestra distribuci√≥n. Cada vez que extraemos una muestra de nuestra distribuci√≥n, terminamos con un valor medio Œº diferente. Por tanto, Œº puede considerarse una variable aleatoria. Un intervalo de confianza con confianza p es un par de valores (L<sub>p</sub>,R<sub>p</sub>), tales que **P**(L<sub>p</sub>&leq;&mu;&leq;R<sub>p</sub>) = p, es decir, una probabilidad de que el valor medio medido caiga dentro del intervalo es igual a p.

M√°s all√° de nuestra breve introducci√≥n, se analiza en detalle c√≥mo se calculan esos intervalos de confianza. Se pueden encontrar algunos detalles m√°s [en Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval) . En resumen, definimos la distribuci√≥n de la media muestral calculada en relaci√≥n con la media verdadera de la poblaci√≥n, lo que se denomina distribuci√≥n de estudiantes.

> **Dato interesante**: La distribuci√≥n estudiantil lleva el nombre del matem√°tico William Sealy Gosset, quien public√≥ su art√≠culo bajo el seud√≥nimo de "Estudiante". Trabajaba en la cervecer√≠a Guinness y, seg√∫n una versi√≥n, su empleador no quer√≠a que el p√∫blico en general supiera que estaban utilizando pruebas estad√≠sticas para determinar la calidad de las materias primas.

Si queremos estimar la media Œº de nuestra poblaci√≥n con confianza p, necesitamos tomar (1-p)/2-√©simo percentil de una distribuci√≥n de Student A, que puede tomarse de tablas o de una computadora usando alg√∫n software incorporado. funciones del software estad√≠stico (por ejemplo, Python, R, etc.). Entonces el intervalo para Œº estar√≠a dado por X¬±A*D/‚àön, donde X es la media obtenida de la muestra, D es la desviaci√≥n est√°ndar.

> **Nota**: Tambi√©n omitimos la discusi√≥n de un concepto importante de grados de libertad , que es importante en relaci√≥n con la distribuci√≥n de Student. Puede consultar libros m√°s completos sobre estad√≠stica para comprender este concepto m√°s profundamente.

[En los cuadernos adjuntos](notebook.ipynb) se proporciona un ejemplo de c√°lculo del intervalo de confianza para pesos y alturas .

| p | Peso medio |
|-----|-----------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Observe que cuanto mayor es la probabilidad de confianza, m√°s amplio es el intervalo de confianza.

## Evaluaci√≥n de la hip√≥tesis

En nuestro conjunto de datos de jugadores de b√©isbol, hay diferentes roles de jugador, que se pueden resumir a continuaci√≥n (consulte  [el cuaderno adjunto](notebook.ipynb) para ver c√≥mo se puede calcular esta tabla):

| Role | Altura | Peso | Contar |
|------|--------|--------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Podemos notar que la altura media de los primera base es mayor que la de la segunda base. Por lo tanto, podemos sentirnos tentados a concluir que los jugadores de primera base son m√°s altos que los de segunda base .

> Esta afirmaci√≥n se llama hip√≥tesis , porque no sabemos si el hecho es realmente cierto o no.

Sin embargo, no siempre es obvio si podemos llegar a esta conclusi√≥n. De la discusi√≥n anterior sabemos que cada media tiene un intervalo de confianza asociado y, por lo tanto, esta diferencia puede ser simplemente un error estad√≠stico. Necesitamos alguna forma m√°s formal de probar nuestra hip√≥tesis.

Calculemos los intervalos de confianza por separado para las alturas de los jugadores de primera y segunda base:

| Confianza | Primera base | Segunda base |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

odemos ver que bajo ninguna confianza los intervalos se superponen. Eso prueba nuestra hip√≥tesis de que los jugadores de primera base son m√°s altos que los de segunda base.

M√°s formalmente, el problema que estamos resolviendo es ver si dos distribuciones de probabilidad son iguales , o al menos tienen los mismos par√°metros. Dependiendo de la distribuci√≥n, necesitamos utilizar diferentes pruebas para ello. Si sabemos que nuestras distribuciones son normales, podemos aplicar **[la prueba t de Studen](https://en.wikipedia.org/wiki/Student%27s_t-test)** .

En la prueba t de Student, calculamos el llamado valor t , que indica la diferencia entre medias, teniendo en cuenta la varianza. Se demuestra que el valor t sigue la distribuci√≥n de Student , lo que nos permite obtener el valor umbral para un nivel de confianza p dado (esto se puede calcular o buscar en las tablas num√©ricas). Luego comparamos el valor t con este umbral para aprobar o rechazar la hip√≥tesis.

En Python, podemos usar el paquete SciPy `ttest_ind`, que incluye funciones (¬°adem√°s de muchas otras funciones estad√≠sticas √∫tiles!). Calcula el valor t por nosotros y tambi√©n realiza la b√∫squeda inversa del valor p de confianza, de modo que podamos simplemente mirar la confianza para sacar la conclusi√≥n.

Por ejemplo, nuestra comparaci√≥n entre las alturas de los jugadores de primera y segunda base nos da los siguientes resultados:

```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```

En nuestro caso, el valor p es muy bajo, lo que significa que existe evidencia s√≥lida que respalda que los jugadores de primera base son m√°s altos.

Tambi√©n existen otros tipos diferentes de hip√≥tesis que podr√≠amos querer probar, por ejemplo:

- Demostrar que una muestra dada sigue alguna distribuci√≥n. En nuestro caso hemos asumido que las alturas se distribuyen normalmente, pero eso necesita una verificaci√≥n estad√≠stica formal.
- Demostrar que un valor medio de una muestra corresponde a alg√∫n valor predefinido
- Comparar medias de varias muestras (por ejemplo, ¬øcu√°l es la diferencia en los niveles de felicidad entre diferentes grupos de edad)?

## Ley de los grandes n√∫meros y teorema del l√≠mite central

Una de las razones por las que la distribuci√≥n normal es tan importante es el llamado teorema del l√≠mite central . Supongamos que tenemos una muestra grande de N valores independientes X 1 , ..., X N , muestreados de cualquier distribuci√≥n con media Œº y varianza œÉ 2 . Entonces, para N suficientemente grande (en otras palabras, cuando N‚Üí‚àû), la media Œ£ i X i estar√≠a distribuida normalmente, con media Œº y varianza œÉ 2 /N.

Otra forma de interpretar el teorema del l√≠mite central es decir que, independientemente de la distribuci√≥n, cuando se calcula la media de una suma de cualquier valor de variable aleatoria se obtiene una distribuci√≥n normal.

Del teorema del l√≠mite central tambi√©n se deduce que, cuando N‚Üí‚àû, la probabilidad de que la media muestral sea igual a Œº se convierte en 1. Esto se conoce como ley de los grandes n√∫meros .

### Covarianza y correlaci√≥n

Una de las cosas que hace la ciencia de datos es encontrar relaciones entre datos. Decimos que dos secuencias se correlacionan cuando exhiben un comportamiento similar al mismo tiempo, es decir, suben o bajan simult√°neamente, o una secuencia sube cuando otra cae y viceversa. En otras palabras, parece haber alguna relaci√≥n entre dos secuencias.

> La correlaci√≥n no indica necesariamente una relaci√≥n causal entre dos secuencias; a veces ambas variables pueden depender de alguna causa externa, o puede ser pura casualidad que las dos secuencias se correlacionen. Sin embargo, una fuerte correlaci√≥n matem√°tica es una buena indicaci√≥n de que dos variables est√°n conectadas de alguna manera.

Matem√°ticamente, el concepto principal que muestra la relaci√≥n entre dos variables aleatorias es la covarianza , que se calcula as√≠: Cov(X,Y) = E [(X- E (X))(Y- E (Y))]. Calculamos la desviaci√≥n de ambas variables de sus valores medios y luego el producto de esas desviaciones. Si ambas variables se desv√≠an juntas, el producto siempre ser√≠a un valor positivo, lo que dar√≠a como resultado una covarianza positiva. Si ambas variables no est√°n sincronizadas (es decir, una cae por debajo del promedio cuando otra se eleva por encima del promedio), siempre obtendremos n√∫meros negativos, que se sumar√°n a una covarianza negativa. Si las desviaciones no son dependientes, suman aproximadamente cero.

El valor absoluto de la covarianza no nos dice mucho sobre qu√© tan grande es la correlaci√≥n, porque depende de la magnitud de los valores reales. Para normalizarlo, podemos dividir la covarianza por la desviaci√≥n est√°ndar de ambas variables, para obtener la correlaci√≥n . Lo bueno es que la correlaci√≥n siempre est√° en el rango de [-1,1], donde 1 indica una fuerte correlaci√≥n positiva entre los valores, -1 - una fuerte correlaci√≥n negativa y 0 - ninguna correlaci√≥n (las variables son independientes).

**Ejemplo**: 1 podemos calcular la correlaci√≥n entre el peso y la altura de los jugadores de b√©isbol a partir del conjnto de datos mencionado anteriormente:

Como resultado, obtenemos una matriz de correlaci√≥n como esta:As  **una matriz de correlaci√≥n** like this one:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

La matriz de correlaci√≥n C se puede calcular para cualquier n√∫mero de secuencias de entrada S 1 , ..., S n . El valor de Cij es la correlaci√≥n entre Si y Sj , y los elementos diagonales son siempre 1 (que tambi√©n es la autocorrelaci√≥n de Si ) .

En nuestro caso, el valor 0,53 indica que existe alguna correlaci√≥n entre el peso y la altura de una persona. Tambi√©n podemos hacer el diagrama de dispersi√≥n de un valor frente al otro para ver la relaci√≥n visualmente:

![Alt text](./img/image8.png)

Conclusi√≥n
En esta secci√≥n hemos aprendido:

- Propiedades estad√≠sticas b√°sicas de los datos, como media, varianza, moda y cuartiles.
- diferentes distribuciones de variables aleatorias, incluida la distribuci√≥n normal
- c√≥mo encontrar correlaci√≥n entre diferentes propiedades
- c√≥mo utilizar aparatos s√≥lidos de matem√°ticas y estad√≠stica para probar algunas hip√≥tesis,
- c√≥mo calcular intervalos de confianza para una variable aleatoria dada una muestra de datos

Si bien esta definitivamente no es una lista exhaustiva de temas que existen dentro de la probabilidad y la estad√≠stica, deber√≠a ser suficiente para darle un buen comienzo en este curso.

üöÄ Desaf√≠o
Utilice el c√≥digo de muestra del cuaderno para probar otras hip√≥tesis que:

1. Los primera base son mayores que los segunda base.
2. Los primera base son m√°s altos que los tercera base.
3. Los campocortos son m√°s altos que los segunda base.

## [Post-lecture quiz](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/7)

## Asignaci√≥n

[Peque√±o estudio sobre diabetes](assignment.md)

## Cr√©ditos

Esta lecci√≥n ha sido escrita con ‚ô•Ô∏è por [Dmitry Soshnikov](http://soshnikov.com)